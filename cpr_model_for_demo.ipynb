{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+h3Gx7v/SswSytM8dsGLh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ba88052/Core_Footprint/blob/main/cpr_model_for_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "28qY62ITBGOC",
        "outputId": "03cbbec6-4385-4492-d79a-f9223c386538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting word2vec\n",
            "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 807 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.2.0)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=156431 sha256=5efb01f09808be16b79fc6b70e5754fa0396b0dc284722ed289d7f3dba87107e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/c0/d4/29d797817e268124a32b6cf8beb8b8fe87b86f099d5a049e61\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.11.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Word2Vec.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#下載word2vec\n",
        "!pip3 install word2vec\n",
        "\n",
        "#import套件\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jieba\n",
        "import word2vec\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "#用於從Dropbox下載檔案\n",
        "def DropboxLink(did, fname):\n",
        "    return 'https://dl.dropboxusercontent.com/s/%s/%s' % \\\n",
        "    (did, fname)\n",
        "\n",
        "def fetch_file_via_requests(url, save_in_dir):\n",
        "    local_filename = url.split('/')[-1]\n",
        "    # NOTE the stream=True parameter below\n",
        "    output_fpath = save_in_dir + local_filename\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(output_fpath, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192): \n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "                    # f.flush()\n",
        "    return output_fpath\n",
        "\n",
        "fetch_file_via_requests(DropboxLink('lwttlehnk5cazkc', 'cola_price_database.csv'), \"\")\n",
        "fetch_file_via_requests(DropboxLink('rpnicxx055lk15p', 'tea_price_database.csv'), \"\")\n",
        "fetch_file_via_requests(DropboxLink('ec816jnmjx5xoxr', 'soy_milk_price_database.csv'), \"\")\n",
        "fetch_file_via_requests(DropboxLink('dfa5z83ghdn5nuh', 'TW_product_core_footprint.csv'), \"\")\n",
        "fetch_file_via_requests(DropboxLink('5fircxkhn4ko9bs', 'Word2Vec.txt'), \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#將csv清理成word2vec所需dataframe\n",
        "def clean_df(df):\n",
        "    df = df[[\"store_name\", \"item_name\", \"avg_price\"]]\n",
        "    store = []\n",
        "    for i in df[\"store_name\"].tolist():\n",
        "        company = re.sub(r\"有限公司.*$\", \"\",str(i))\n",
        "        company = re.sub(r\"股份.*$\", \"\",company)\n",
        "        store.append(company)\n",
        "    df[\"store_name\"] = store\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    return df\n",
        "\n",
        "#使用word2vec將文字向量化\n",
        "def from_df_to_vec(df): \n",
        "    model = word2vec.load('Word2Vec.txt')\n",
        "    df = clean_df(df)\n",
        "    words = df[\"item_name\"].apply(lambda x: list(jieba.cut(str(x), HMM=True)))\n",
        "    chi_stopword = ['!',',','.','?','-s','-ly','>','<','</s>','s', '-', \"+\", \"_\", \"-\", \"[\",\"]\", \"/\", \"(\", \")\", \"*\", \"–\", \" \", \"＊\", \"【\" , \"】\", \"（\", \"）\"]\n",
        "    words = words.apply(lambda x: [word for word in x if word not in chi_stopword])\n",
        "    words = words.reset_index(drop = True)\n",
        "    words_list = []\n",
        "    for i in words:\n",
        "        li = []\n",
        "        for l in i:\n",
        "            # print(l)\n",
        "            try:\n",
        "                li.append(model[l])\n",
        "                length = len(li)\n",
        "            except:\n",
        "                length = length-1\n",
        "                print(l)\n",
        "                continue\n",
        "        if length < 1:\n",
        "            words_list.append(0)\n",
        "        else:\n",
        "            words_list.append(sum(li)/length)\n",
        "    pd_list = []\n",
        "    for i in range(1, 101):\n",
        "        pd_list.append(str(i))\n",
        "    vec_df = pd.DataFrame(columns = pd_list)\n",
        "\n",
        "    for i in range(len(words_list)):\n",
        "        for l in range(len(words_list[i])):\n",
        "            vec_df.loc[i, str(l+1)] = words_list[i][l]\n",
        "    vec_df = vec_df.fillna(0)\n",
        "\n",
        "    test_product_df = df.reset_index(drop = True)\n",
        "    vec_df = vec_df.merge(test_product_df, how='inner', left_index=True, right_index=True)\n",
        "    # vec_df = vec_df.drop(\"item_name\", axis = 1)\n",
        "    return(vec_df)\n",
        "\n",
        "#串接雲端貝果的API\n",
        "def pcr_model(data_in_dict):\n",
        "    #API網址    \n",
        "    url = \"https://decanter.ai/v1/prediction/single_predict\"\n",
        "\n",
        "    #標頭\n",
        "    headers = {\"accept\": \"application/json\",\n",
        "                \"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoiNjMzM2RiZTFjYmZjOWZiMzZjY2QyODFhIiwiaXNzIjoiZ3AtYmUiLCJzdWIiOiJhcGlrZXkiLCJhdWQiOiJjbGllbnQiLCJpYXQiOjE2NjQzNDMwMDkuNzEwMTI0fQ.RJhUFroa12kbjBeREHC0nStBRRQGrWRDRAvJ3C9wIO4\" ,\n",
        "                \"Content-Type\": \"application/json\"}\n",
        "    #參數\n",
        "    data = {\"project_id\":\"63351e334a539a13493529b6\",\"model_id\":\"633a6a94cbfc9fb36ccd29cc\",    \n",
        "            \"features\":data_in_dict}\n",
        "    access_token = requests.post(url, headers=headers, json=data)\n",
        "    return access_token.json()[\"single_predict_result\"][0][\"result\"][\"prediction\"]\n",
        "def cola_database_model(data_in_dict):\n",
        "    #API網址    \n",
        "    url = \"https://decanter.ai/v1/prediction/single_predict\"\n",
        "\n",
        "    #標頭\n",
        "    headers = {\"accept\": \"application/json\",\n",
        "                \"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoiNjMzM2RiZTFjYmZjOWZiMzZjY2QyODFhIiwiaXNzIjoiZ3AtYmUiLCJzdWIiOiJhcGlrZXkiLCJhdWQiOiJjbGllbnQiLCJpYXQiOjE2NjQzNDMwMDkuNzEwMTI0fQ.RJhUFroa12kbjBeREHC0nStBRRQGrWRDRAvJ3C9wIO4\" ,\n",
        "                \"Content-Type\": \"application/json\"}\n",
        "    #參數\n",
        "    data = {\"project_id\":\"63351e334a539a13493529b6\",\"model_id\":\"633bf818a5810cafb3fb26de\",    \n",
        "            \"features\":data_in_dict}\n",
        "    access_token = requests.post(url, headers=headers, json=data)\n",
        "    return access_token.json()[\"single_predict_result\"][0][\"result\"][\"prediction\"]\n",
        "def tea_database_model(data_in_dict):\n",
        "    #API網址    \n",
        "    url = \"https://decanter.ai/v1/prediction/single_predict\"\n",
        "\n",
        "    #標頭\n",
        "    headers = {\"accept\": \"application/json\",\n",
        "                \"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoiNjMzM2RiZTFjYmZjOWZiMzZjY2QyODFhIiwiaXNzIjoiZ3AtYmUiLCJzdWIiOiJhcGlrZXkiLCJhdWQiOiJjbGllbnQiLCJpYXQiOjE2NjQzNDMwMDkuNzEwMTI0fQ.RJhUFroa12kbjBeREHC0nStBRRQGrWRDRAvJ3C9wIO4\" ,\n",
        "                \"Content-Type\": \"application/json\"}\n",
        "    #參數\n",
        "    data = {\"project_id\":\"63351e334a539a13493529b6\",\"model_id\":\"633bef1822620955cfae65f7\",    \n",
        "            \"features\":data_in_dict}\n",
        "    access_token = requests.post(url, headers=headers, json=data)\n",
        "    return access_token.json()[\"single_predict_result\"][0][\"result\"][\"prediction\"]\n",
        "def soymilk_database_model(data_in_dict):\n",
        "    #API網址    \n",
        "    url = \"https://decanter.ai/v1/prediction/single_predict\"\n",
        "\n",
        "    #標頭\n",
        "    headers = {\"accept\": \"application/json\",\n",
        "                \"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoiNjMzM2RiZTFjYmZjOWZiMzZjY2QyODFhIiwiaXNzIjoiZ3AtYmUiLCJzdWIiOiJhcGlrZXkiLCJhdWQiOiJjbGllbnQiLCJpYXQiOjE2NjQzNDMwMDkuNzEwMTI0fQ.RJhUFroa12kbjBeREHC0nStBRRQGrWRDRAvJ3C9wIO4\" ,\n",
        "                \"Content-Type\": \"application/json\"}\n",
        "    #參數\n",
        "    data = {\"project_id\":\"63351e334a539a13493529b6\",\"model_id\":\"633be78722620955cfae65ec\",    \n",
        "            \"features\":data_in_dict}\n",
        "    access_token = requests.post(url, headers=headers, json=data)\n",
        "    return access_token.json()[\"single_predict_result\"][0][\"result\"][\"prediction\"]\n",
        "\n",
        "#運用雲端貝果模型進行預測\n",
        "def get_PCRclass_and_databaseid(bill_df):\n",
        "    pcr_li = []\n",
        "    database_id_li = []\n",
        "    bill_df_vec = from_df_to_vec(bill_df)\n",
        "    for i in bill_df_vec.to_dict(\"index\"):\n",
        "        bill_data = bill_df_vec.to_dict(\"index\")[i]\n",
        "        pcr_id = float(pcr_model(bill_data))\n",
        "        pcr_li.append(pcr_id)\n",
        "        if pcr_id == 1:\n",
        "            database_id_li.append(cola_database_model(bill_data))\n",
        "        elif pcr_id == 2:\n",
        "            database_id_li.append(tea_database_model(bill_data))\n",
        "        elif pcr_id == 3:\n",
        "            database_id_li.append(soymilk_database_model(bill_data))\n",
        "        else:\n",
        "            database_id_li.append(-1.0)\n",
        "    bill_ans = pd.DataFrame(columns = [\"store_name\", \"store_num\", \"store_address\", \"item_name\", \"avg_price\", \"pcr\", \"database_id\"], data = bill_df)\n",
        "    bill_ans[\"pcr\"] = pcr_li\n",
        "    bill_ans[\"database_id\"] = database_id_li\n",
        "    return bill_ans\n",
        "\n",
        "#從資料庫獲取PCR每個分類的每元碳足跡\n",
        "def get_pcr_mean_fp():\n",
        "    cola_price_ml_mean = pd.read_csv(\"cola_price_database.csv\")[\"unit/avg_price\"].mean()\n",
        "    tea_price_ml_mean = pd.read_csv(\"tea_price_database.csv\")[\"unit/avg_price\"].mean()\n",
        "    soymilk_price_ml_mean = pd.read_csv(\"soy_milk_price_database.csv\")[\"unit/avg_price\"].mean()\n",
        "    tw_fp = pd.read_csv(\"TW_product_core_footprint.csv\")\n",
        "    tw_pcr_mean_fp = tw_fp.groupby(\"pcr_class_id\").mean()[\"cpr/unit\"].reset_index()\n",
        "    tw_pcr_mean_fp[\"price_eachunit\"] = [cola_price_ml_mean, tea_price_ml_mean, soymilk_price_ml_mean]\n",
        "    tw_pcr_mean_fp[\"cpr_eachprice\"] = tw_pcr_mean_fp[\"cpr/unit\"] * tw_pcr_mean_fp[\"price_eachunit\"]\n",
        "    return(tw_pcr_mean_fp)\n",
        "def get_bill_cpr(bill_df):\n",
        "    tw_pcr_mean_fp = get_pcr_mean_fp()\n",
        "    bill_ans = get_PCRclass_and_databaseid(bill_df)\n",
        "    product_core_footprint_li = []\n",
        "    tw_fp = pd.read_csv(\"TW_product_core_footprint.csv\")\n",
        "    for index in bill_ans.index:\n",
        "        database_id = float(bill_ans.loc[index, \"database_id\"])\n",
        "        pcr_id = bill_ans.loc[index, \"pcr\"]\n",
        "        if database_id == -1:\n",
        "            if pcr_id > 0:\n",
        "                product_core_footprint_li.append(\n",
        "                    tw_pcr_mean_fp[tw_pcr_mean_fp[\"pcr_class_id\"] == pcr_id][\"cpr_eachprice\"].values[0]*bill_ans.loc[index, \"avg_price\"])\n",
        "            else:\n",
        "                product_core_footprint_li.append(np.nan)\n",
        "        else:\n",
        "            product_core_footprint_li.append(\n",
        "                tw_fp[tw_fp[\"item_id\"] == database_id][\"cpr(kg)\"].values[0])\n",
        "    bill_ans[\"product_core_footprint\"] = product_core_footprint_li\n",
        "    return(bill_ans)"
      ],
      "metadata": {
        "id": "CnSvjDBwBReR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#下載Demo資料\n",
        "fetch_file_via_requests(DropboxLink('1ldepgd5cm7m1rf', 'bill_for_demo.csv'), \"\")\n",
        "\n",
        "#運算並儲存csv\n",
        "answer = get_bill_cpr(pd.read_csv(\"bill_for_demo.csv\"))\n",
        "answer.to_csv(\"demo_answer.csv\")\n",
        "answer"
      ],
      "metadata": {
        "id": "TCvWAEodCP9l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}